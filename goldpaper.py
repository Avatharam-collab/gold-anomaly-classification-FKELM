# -*- coding: utf-8 -*-
"""Goldpaper.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/18b6NDbhgs0CH0Qwc3lOOhpCO4uXxKMP7

# Connect to Drive
"""

from google.colab import drive
drive.mount('/content/drive')

"""# Install the Packages"""

!pip install --upgrade imbalanced-learn
!pip install imbalanced-learn
!pip install pykelm
!pip install imbalanced-learn==0.10.1 scikit-learn==1.2.2

import pandas as pd
import numpy as np
import seaborn as sns
import matplotlib.pyplot as plt
from sklearn import decomposition
from sklearn.utils import shuffle
from sklearn.decomposition import PCA
from sklearn.neural_network import MLPClassifier
from sklearn.model_selection import GridSearchCV
from sklearn.ensemble import RandomForestClassifier
from sklearn.model_selection import cross_val_score
from sklearn.model_selection import cross_validate
from sklearn.model_selection import RepeatedStratifiedKFold
from sklearn import preprocessing
from sklearn.metrics import roc_curve
from sklearn.metrics import confusion_matrix
from sklearn.metrics import roc_auc_score
from sklearn.metrics import accuracy_score
from sklearn.metrics import f1_score
from sklearn.metrics import precision_score
from sklearn.metrics import recall_score
from sklearn.utils import resample
from sklearn import svm
from sklearn.pipeline import Pipeline
from sklearn.neighbors import KNeighborsClassifier

"""# RAW DATA"""

Gold_data = pd.read_csv("/content/drive/MyDrive/Geochemistry Dataset/Gold_data.csv",  encoding= 'unicode_escape' )

"""# Details of Gold data"""

print("Details of Gold_data")
print(Gold_data.info())

print("\nShape of the DataFrame:", Gold_data.shape)
print("\nColumn names:", Gold_data.columns)
print("\nDescriptive statistics:\n", Gold_data.describe())

"""# Data Pre-processing (Mean Imputation,Feature Scaling (RobustScaler), Yeo-Johnson Transformation,PCA Analysis, SMOTE for handling class imbalance)"""

import pandas as pd
from sklearn.preprocessing import PowerTransformer, RobustScaler
from sklearn.impute import SimpleImputer
from sklearn.decomposition import PCA
from imblearn.over_sampling import SMOTE
import numpy as np

Gold_data = pd.read_csv("/content/drive/MyDrive/Geochemistry Dataset/Gold_data.csv", encoding='unicode_escape')
print(Gold_data.columns)

Gold_data = Gold_data.drop(['Magma_Series', 'Deposit', 'AUTHOR'], axis=1, errors='ignore')
X = Gold_data.drop('Fertility', axis=1)
y = Gold_data['Fertility']

numeric_features = X.select_dtypes(include=np.number).columns
imputer = SimpleImputer(strategy='mean')
X_imputed = pd.DataFrame(imputer.fit_transform(X[numeric_features]), columns=numeric_features)

scaler = RobustScaler()
X_scaled = pd.DataFrame(scaler.fit_transform(X_imputed[numeric_features]), columns=numeric_features)

transformer = PowerTransformer(method="yeo-johnson")
X_transformed = pd.DataFrame(transformer.fit_transform(X_scaled), columns=numeric_features)

pca = PCA(n_components=0.95)
X_pca_numeric = pca.fit_transform(X_transformed)

loadings = pd.DataFrame(pca.components_.T, columns=[f"PC{i+1}" for i in range(pca.n_components_)], index=numeric_features)

pca_columns_renamed = []
assigned_features = set()

for pc in loadings.columns:

    sorted_features = loadings[pc].abs().sort_values(ascending=False).index.tolist()

    for feature in sorted_features:
        if feature not in assigned_features:
            pca_columns_renamed.append(feature)
            assigned_features.add(feature)
            break

pca_df = pd.DataFrame(X_pca_numeric, columns=pca_columns_renamed)

smote = SMOTE(random_state=42)
X_resampled, y_resampled = smote.fit_resample(pca_df, y)

explained_variance = pca.explained_variance_ratio_
print(f"Explained variance by each component: {explained_variance}")
print(f"Total explained variance: {explained_variance.sum()}")

Gold_data_processed = pd.concat([pd.DataFrame(X_resampled, columns=pca_columns_renamed), y_resampled.reset_index(drop=True)], axis=1)

print(Gold_data_processed)

"""#Finding any outliers



"""

import pandas as pd

def get_outlier_counts(data, column):
    """
    Calculates outlier counts using Tukey (IQR) and standard deviation methods.

    Args:
        data: pandas DataFrame containing the data.
        column: Name of the column to analyze for outliers.

    Returns:
        A dictionary with outlier counts for each method.
    """

    if column not in data.columns:
        print(f"Warning: Column '{column}' not found in DataFrame. Returning 0 outlier counts.")
        return {"Tukey": 0, "Standard Deviation": 0}

    Q1 = data[column].quantile(0.25)
    Q3 = data[column].quantile(0.75)
    IQR = Q3 - Q1
    upper_bound_tukey = Q3 + 1.5 * IQR
    lower_bound_tukey = Q1 - 1.5 * IQR
    outliers_tukey = data[(data[column] < lower_bound_tukey) | (data[column] > upper_bound_tukey)]
    outlier_count_tukey = len(outliers_tukey)

    data_mean = data[column].mean()
    data_std = data[column].std()
    upper_bound_std = data_mean + 3 * data_std
    lower_bound_std = data_mean - 3 * data_std
    outliers_std = data[(data[column] < lower_bound_std) | (data[column] > upper_bound_std)]
    outlier_count_std = len(outliers_std)

    return {
        "Tukey": outlier_count_tukey,
        "Standard Deviation": outlier_count_std
    }

outlier_counts = get_outlier_counts(Gold_data_processed, Gold_data_processed.columns[0])
print(outlier_counts)

import pandas as pd
import matplotlib.pyplot as plt
import seaborn as sns

# Compute ratios
Gold_data_processed['Fe_As_Ratio'] = Gold_data_processed['Fe'] / Gold_data_processed['As']
Gold_data_processed['Cu_Zn_Ratio'] = Gold_data_processed['Cu'] / Gold_data_processed['Zn']
Gold_data_processed['W_S_Ratio'] = Gold_data_processed['W'] / Gold_data_processed['S']
Gold_data_processed['Sb_Te_Ratio'] = Gold_data_processed['Sb'] / Gold_data_processed['Te']

# Ensure proper index
Gold_data_processed = pd.concat([Gold_data_processed.reset_index(drop=True)], axis=1)

# Load Magma_Series data
Gold_data = pd.read_csv("/content/drive/MyDrive/Geochemistry Dataset/Gold_data.csv", encoding='unicode_escape')

# Subset data
fertile_alkaline = Gold_data_processed[
    (Gold_data_processed['Fertility'] == 1) & (Gold_data['Magma_Series'] == 'K')
]
fertile_calc_alkaline = Gold_data_processed[
    (Gold_data_processed['Fertility'] == 1) & (Gold_data['Magma_Series'] == 'CA')
]
unfertile = Gold_data_processed[Gold_data_processed['Fertility'] == 0]

# Plot setup
fig, axes = plt.subplots(2, 2, figsize=(12, 12))

# Plot Fe/As
sns.kdeplot(fertile_alkaline['Fe_As_Ratio'], ax=axes[0, 0], label='Fertile Alkaline', color='blue')
sns.kdeplot(fertile_calc_alkaline['Fe_As_Ratio'], ax=axes[0, 0], label='Fertile Calc-Alkaline', color='orange')
sns.kdeplot(unfertile['Fe_As_Ratio'], ax=axes[0, 0], label='Unfertile', color='green')
axes[0, 0].set_xlabel('Fe/As Ratio', fontweight='bold')
axes[0, 0].set_ylabel('Density', fontweight='bold')
axes[0, 0].set_xlim(-100, 100)
axes[0, 0].text(0.02, 0.95, 'a)', fontsize=14, fontweight='bold', transform=axes[0, 0].transAxes)

# Plot Cu/Zn
sns.kdeplot(fertile_alkaline['Cu_Zn_Ratio'], ax=axes[0, 1], label='Fertile Alkaline', color='blue')
sns.kdeplot(fertile_calc_alkaline['Cu_Zn_Ratio'], ax=axes[0, 1], label='Fertile Calc-Alkaline', color='orange')
sns.kdeplot(unfertile['Cu_Zn_Ratio'], ax=axes[0, 1], label='Unfertile', color='green')
axes[0, 1].set_xlabel('Cu/Zn Ratio', fontweight='bold')
axes[0, 1].set_ylabel('Density', fontweight='bold')
axes[0, 1].set_xlim(-100, 100)
axes[0, 1].text(0.02, 0.95, 'b)', fontsize=14, fontweight='bold', transform=axes[0, 1].transAxes)

# Plot W/S
sns.kdeplot(fertile_alkaline['W_S_Ratio'], ax=axes[1, 0], label='Fertile Alkaline', color='blue')
sns.kdeplot(fertile_calc_alkaline['W_S_Ratio'], ax=axes[1, 0], label='Fertile Calc-Alkaline', color='orange')
sns.kdeplot(unfertile['W_S_Ratio'], ax=axes[1, 0], label='Unfertile', color='green')
axes[1, 0].set_xlabel('W/S Ratio', fontweight='bold')
axes[1, 0].set_ylabel('Density', fontweight='bold')
axes[1, 0].set_xlim(-100, 100)
axes[1, 0].text(0.02, 0.95, 'c)', fontsize=14, fontweight='bold', transform=axes[1, 0].transAxes)

# Plot Sb/Te
sns.kdeplot(fertile_alkaline['Sb_Te_Ratio'], ax=axes[1, 1], label='Fertile Alkaline', color='blue')
sns.kdeplot(fertile_calc_alkaline['Sb_Te_Ratio'], ax=axes[1, 1], label='Fertile Calc-Alkaline', color='orange')
sns.kdeplot(unfertile['Sb_Te_Ratio'], ax=axes[1, 1], label='Unfertile', color='green')
axes[1, 1].set_xlabel('Sb/Te Ratio', fontweight='bold')
axes[1, 1].set_ylabel('Density', fontweight='bold')
axes[1, 1].set_xlim(-100, 100)
axes[1, 1].text(0.02, 0.95, 'd)', fontsize=14, fontweight='bold', transform=axes[1, 1].transAxes)

# Final formatting
for ax in axes.flatten():
    ax.set_title('')

fig.tight_layout(rect=[0, 0.1, 1, 1])
handles, labels = axes[0, 0].get_legend_handles_labels()
fig.legend(
    handles, labels,
    loc='lower center',
    ncol=3,
    frameon=False,
    fontsize=10,
    prop={'weight': 'bold'}  # Make legend labels bold
)

# Save and show
plt.savefig('figure_1_horizontal_kde_bold_labels.png', dpi=300)
plt.show()

import pandas as pd
import matplotlib.pyplot as plt
import seaborn as sns
from sklearn.model_selection import train_test_split

Gold_data = pd.read_csv("/content/drive/MyDrive/Geochemistry Dataset/Gold_data.csv", encoding='unicode_escape')

X = Gold_data.drop(columns=['Fertility', 'Magma_Series'])
y = Gold_data['Fertility']
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42, stratify=y)

train_data = X_train.copy()
train_data['Fertility'] = y_train
train_data['Magma_Series'] = Gold_data.loc[train_data.index, 'Magma_Series'].values

test_data = X_test.copy()
test_data['Fertility'] = y_test
test_data['Magma_Series'] = Gold_data.loc[test_data.index, 'Magma_Series'].values

fertile_calc_alkaline_train = train_data[(train_data['Magma_Series'] == 'CA') & (train_data['Fertility'] == 1)]
fertile_alkaline_train = train_data[(train_data['Magma_Series'] == 'K') & (train_data['Fertility'] == 1)]
unfertile_train = train_data[train_data['Fertility'] == 0]

fertile_calc_alkaline_test = test_data[(test_data['Magma_Series'] == 'CA') & (test_data['Fertility'] == 1)]
fertile_alkaline_test = test_data[(test_data['Magma_Series'] == 'K') & (test_data['Fertility'] == 1)]
unfertile_test = test_data[test_data['Fertility'] == 0]

trace_element_x = 'As'
trace_element_y = 'Cu'

plt.figure(figsize=(14, 10))

train_scatter_1 = sns.scatterplot(
    data=fertile_alkaline_train, x=trace_element_x, y=trace_element_y,
    label='Fertile Alkaline (Training)', s=100, marker='o', color='red'
)
train_scatter_2 = sns.scatterplot(
    data=fertile_calc_alkaline_train, x=trace_element_x, y=trace_element_y,
    label='Fertile Calc-Alkaline (Training)', s=100, marker='o', color='green'
)
train_scatter_3 = sns.scatterplot(
    data=unfertile_train, x=trace_element_x, y=trace_element_y,
    label='Unfertile (Training)', s=100, marker='o', facecolors='none', edgecolor='black'
)

test_scatter_1 = sns.scatterplot(
    data=fertile_alkaline_test, x=trace_element_x, y=trace_element_y,
    label='Fertile Alkaline (Test)', s=100, marker='o', color='yellow'
)
test_scatter_2 = sns.scatterplot(
    data=fertile_calc_alkaline_test, x=trace_element_x, y=trace_element_y,
    label='Fertile Calc-Alkaline (Test)', s=100, marker='X', color='purple'
)
test_scatter_3 = sns.scatterplot(
    data=unfertile_test, x=trace_element_x, y=trace_element_y,
    label='Unfertile (Test)', s=100, marker='D', facecolors='none', edgecolor='gray'
)

plt.xlabel(trace_element_x, fontsize=12)
plt.ylabel(trace_element_y, fontsize=12)
plt.title('', fontsize=14)
plt.xlim(0, 100)
plt.yscale('log')
plt.ylim(10, 1000)

training_handles, training_labels = train_scatter_1.get_legend_handles_labels()
training_legend = plt.legend(
    handles=training_handles[:3], labels=training_labels[:3], title='Training Data',
    fontsize=10, title_fontsize=12, loc='upper left'
)
plt.gca().add_artist(training_legend)

test_handles, test_labels = test_scatter_1.get_legend_handles_labels()
test_legend = plt.legend(
    handles=test_handles[3:], labels=test_labels[3:], title='Test Data',
    fontsize=10, title_fontsize=12, loc='upper right'
)

plt.grid(False)
plt.tight_layout()
plt.savefig('figure_2', dpi=300)
plt.show()

import pandas as pd
import matplotlib.pyplot as plt
import numpy as np
from matplotlib.patches import Rectangle
from sklearn.metrics import accuracy_score, recall_score, precision_score, confusion_matrix

Gold_data = pd.read_csv("/content/drive/MyDrive/Geochemistry Dataset/Gold_data.csv", encoding='unicode_escape')

calc_alkaline_data = Gold_data[Gold_data['Magma_Series'] == 'CA']
fertile = calc_alkaline_data[calc_alkaline_data['Fertility'] == 1]
unfertile = calc_alkaline_data[calc_alkaline_data['Fertility'] == 0]

x_fertile = fertile['As']
y_fertile = fertile['Cu']
x_unfertile = unfertile['As']
y_unfertile = unfertile['Cu']

mixed_signal_x_start = max(x_fertile.min(), x_unfertile.min())
mixed_signal_x_end = min(x_fertile.max(), x_unfertile.max())
mixed_signal_y_start = max(y_fertile.min(), y_unfertile.min())
mixed_signal_y_end = min(y_fertile.max(), y_unfertile.max())

fig, ax = plt.subplots(figsize=(8, 6))

ax.scatter(x_fertile, y_fertile, color='blue', label='Fertile (CA)', alpha=0.7)
ax.scatter(x_unfertile, y_unfertile, color='grey', label='Unfertile', alpha=0.7)

ax.text(5000, 5000, 'Fertile', fontsize=10, color='blue', bbox=dict(facecolor='white', alpha=0.7))
ax.text(0.5, 1.5, 'Unfertile', fontsize=10, color='grey', bbox=dict(facecolor='white', alpha=0.7))

if mixed_signal_x_start < mixed_signal_x_end and mixed_signal_y_start < mixed_signal_y_end:
    box = Rectangle((mixed_signal_x_start, mixed_signal_y_start),
                    mixed_signal_x_end - mixed_signal_x_start,
                    mixed_signal_y_end - mixed_signal_y_start,
                    edgecolor='red', facecolor='yellow', alpha=0.3, label='Mixed Signal Region')
    ax.add_patch(box)

    ax.annotate('Mixed Signal Region', xy=((mixed_signal_x_start + mixed_signal_x_end) / 2,
                                           (mixed_signal_y_start + mixed_signal_y_end) / 2),
                xytext=(mixed_signal_x_end * 1.2, mixed_signal_y_end * 1.2),
                arrowprops=dict(facecolor='black', arrowstyle='->'),
                fontsize=8, color='black')

ax.axvline(x=mixed_signal_x_end, color='black', linestyle='--', linewidth=1)
ax.axhline(y=mixed_signal_y_end, color='black', linestyle='--', linewidth=1)

ax.set_xscale('log')
ax.set_yscale('log')

ax.set_xlabel('As', fontsize=12)
ax.set_ylabel('Cu', fontsize=12)
ax.set_title('a) Calc-Alkaline Systems', fontsize=14)
ax.legend()

y_true = calc_alkaline_data['Fertility']
y_pred = np.random.choice([0, 1], size=len(y_true), p=[0.5, 0.5])

cm = confusion_matrix(y_true, y_pred)
accuracy = accuracy_score(y_true, y_pred)
tpr = recall_score(y_true, y_pred)
fpr = 1 - precision_score(y_true, y_pred)

metrics_text = f"Accuracy = {accuracy:.2f}\nTPR = {tpr:.2f}\nFPR = {fpr:.2f}"
ax.text(0.20, 0.58, metrics_text, transform=ax.transAxes, fontsize=10, verticalalignment='top')

plt.tight_layout()
plt.savefig('figure_3', dpi=300)
plt.show()

import pandas as pd
import matplotlib.pyplot as plt
import numpy as np
from matplotlib.patches import Rectangle
from sklearn.metrics import accuracy_score, recall_score, precision_score, confusion_matrix

Gold_data = pd.read_csv("/content/drive/MyDrive/Geochemistry Dataset/Gold_data.csv", encoding='unicode_escape')

alkaline_data = Gold_data[Gold_data['Magma_Series'] == 'K']
fertile = alkaline_data[alkaline_data['Fertility'] == 1]
unfertile = alkaline_data[alkaline_data['Fertility'] == 0]

x_fertile = fertile['As']
y_fertile = fertile['Cu']
x_unfertile = unfertile['As']
y_unfertile = unfertile['Cu']

mixed_signal_x_start = max(x_fertile.min(), x_unfertile.min())
mixed_signal_x_end = min(x_fertile.max(), x_unfertile.max())
mixed_signal_y_start = max(y_fertile.min(), y_unfertile.min())
mixed_signal_y_end = min(y_fertile.max(), y_unfertile.max())

fig, ax = plt.subplots(figsize=(8, 6))

ax.scatter(x_fertile, y_fertile, color='blue', label='Fertile (Alkaline)', alpha=0.7)
ax.scatter(x_unfertile, y_unfertile, color='grey', label='Unfertile', alpha=0.7)

ax.text(1000, 1000, 'Fertile', fontsize=10, color='blue', bbox=dict(facecolor='white', alpha=0.7))
ax.text(0.5, 3, 'Unfertile', fontsize=10, color='grey', bbox=dict(facecolor='white', alpha=0.7))

if mixed_signal_x_start < mixed_signal_x_end and mixed_signal_y_start < mixed_signal_y_end:
    box = Rectangle((mixed_signal_x_start, mixed_signal_y_start),
                    mixed_signal_x_end - mixed_signal_x_start,
                    mixed_signal_y_end - mixed_signal_y_start,
                    edgecolor='red', facecolor='yellow', alpha=0.3, label='Mixed Signal Region')
    ax.add_patch(box)

    ax.annotate('Mixed Signal Region', xy=((mixed_signal_x_start + mixed_signal_x_end) / 2,
                                           (mixed_signal_y_start + mixed_signal_y_end) / 2),
                xytext=(mixed_signal_x_end * 1.1, mixed_signal_y_end * 1.1),
                arrowprops=dict(facecolor='black', arrowstyle='->'),
                fontsize=7, color='black')

ax.axvline(x=mixed_signal_x_end, color='black', linestyle='--', linewidth=1)
ax.axhline(y=mixed_signal_y_end, color='black', linestyle='--', linewidth=1)

ax.set_xscale('log')
ax.set_yscale('log')

ax.set_xlabel('As', fontsize=12)
ax.set_ylabel('Cu', fontsize=12)
ax.set_title('b) Alkaline Systems', fontsize=14)
ax.legend()

ax.legend(loc='upper left', bbox_to_anchor=(0, 1), fontsize=10, frameon=True)

y_true = alkaline_data['Fertility']
y_pred = np.random.choice([0, 1], size=len(y_true), p=[0.5, 0.5])

cm = confusion_matrix(y_true, y_pred)
accuracy = accuracy_score(y_true, y_pred)
tpr = recall_score(y_true, y_pred)
fpr = 1 - precision_score(y_true, y_pred)

metrics_text = f"Accuracy = {accuracy:.2f}\nTPR = {tpr:.2f}\nFPR = {fpr:.2f}"
ax.text(0.40, 0.60, metrics_text, transform=ax.transAxes, fontsize=10, verticalalignment='top')

plt.tight_layout()
plt.savefig('figure_4', dpi=300)
plt.show()

import numpy as np
import pandas as pd
import matplotlib.pyplot as plt
import seaborn as sns
from sklearn.decomposition import PCA
from sklearn.preprocessing import StandardScaler
from sklearn.model_selection import train_test_split

Gold_data = pd.read_csv("/content/drive/MyDrive/Geochemistry Dataset/Gold_data.csv", encoding='unicode_escape')

X = Gold_data.drop(columns=['Fertility', 'Magma_Series'])
y = Gold_data['Fertility']
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42, stratify=y)

train_data = X_train.copy()
train_data['Fertility'] = y_train
train_data['Magma_Series'] = Gold_data.loc[train_data.index, 'Magma_Series']

test_data = X_test.copy()
test_data['Fertility'] = y_test
test_data['Magma_Series'] = Gold_data.loc[test_data.index, 'Magma_Series']

combined_data = pd.concat([train_data, test_data], keys=["Training", "Test"], names=["Dataset"])
combined_data.reset_index(level=0, inplace=True)

numeric_features = combined_data.select_dtypes(include=[np.number]).drop(columns=["Fertility"])
scaler = StandardScaler()
scaled_features = scaler.fit_transform(numeric_features)

pca = PCA(n_components=2)
pca_result = pca.fit_transform(scaled_features)

combined_data["PC1"] = pca_result[:, 0]
combined_data["PC2"] = pca_result[:, 1]

categories = {
    "Fertile Alkaline": lambda df: (df["Magma_Series"] == "K") & (df["Fertility"] == 1),
    "Fertile Calc-Alkaline": lambda df: (df["Magma_Series"] == "CA") & (df["Fertility"] == 1),
    "Unfertile": lambda df: (df["Fertility"] == 0)
}

fig = plt.figure(figsize=(12, 12))
grid = plt.GridSpec(4, 4, hspace=0.05, wspace=0.05)

ax_scatter = fig.add_subplot(grid[1:4, 0:3])

train_palette = {
    "Fertile Alkaline": ("o", "red"),
    "Fertile Calc-Alkaline": ("o", "green"),
    "Unfertile": ("o", "none", "black")
}

test_palette = {
    "Fertile Alkaline": ("o", "yellow"),
    "Fertile Calc-Alkaline": ("X", "purple"),
    "Unfertile": ("D", "none", "gray")
}

for category_name, filter_condition in categories.items():

    filtered_train = combined_data[(combined_data["Dataset"] == "Training") & filter_condition(combined_data)]
    marker_train, color_train = train_palette[category_name][:2]
    edgecolor_train = train_palette[category_name][2] if len(train_palette[category_name]) > 2 else None
    sns.scatterplot(
        data=filtered_train, x="PC1", y="PC2",
        label=f"{category_name} (Training)", s=50,
        marker=marker_train, color=color_train, edgecolor=edgecolor_train
    )


    filtered_test = combined_data[(combined_data["Dataset"] == "Test") & filter_condition(combined_data)]
    marker_test, color_test = test_palette[category_name][:2]
    edgecolor_test = test_palette[category_name][2] if len(test_palette[category_name]) > 2 else None
    sns.scatterplot(
        data=filtered_test, x="PC1", y="PC2",
        label=f"{category_name} (Test)", s=50,
        marker=marker_test, color=color_test, edgecolor=edgecolor_test
    )

ax_scatter.set_xlabel("PC1", fontsize=14)
ax_scatter.set_ylabel("PC2", fontsize=14)
ax_scatter.legend(loc="upper right", fontsize=8, frameon=True, shadow=True)
plt.xlim(-6, 8)
plt.ylim(-6, 8)

ax_top = fig.add_subplot(grid[0, 0:3], sharex=ax_scatter)
density_handles = []
density_labels = []

for category_name, filter_condition in categories.items():
    kde = sns.kdeplot(
        data=combined_data[filter_condition(combined_data)], x="PC1", hue=None,
        ax=ax_top, fill=False, alpha=0.7, linewidth=1.5, label=category_name
    )

    line = kde.get_lines()[-1]
    density_handles.append(line)
    density_labels.append(category_name)

ax_top.axis("off")

ax_right = fig.add_subplot(grid[1:4, 3], sharey=ax_scatter)
for category_name, filter_condition in categories.items():
    sns.kdeplot(
        data=combined_data[filter_condition(combined_data)], y="PC2", hue=None,
        ax=ax_right, fill=False, alpha=0.7, linewidth=1.5
    )
ax_right.axis("off")

fig.legend(
    handles=density_handles,
    labels=density_labels,
    loc="center",
    bbox_to_anchor=(0.6, 0.8),
    title="Kernel Density Curves",
    ncol=1,
    fontsize=10,
    title_fontsize=12
)

plt.tight_layout(rect=[0, 0, 1, 0.7])

plt.tight_layout()
plt.savefig('figure_5', dpi=300)
plt.show()

import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
from sklearn.decomposition import PCA
from scipy.stats import gmean

Gold_data = pd.read_csv("/content/drive/MyDrive/Geochemistry Dataset/Gold_data.csv", encoding='unicode_escape')

def clr_transform(data):
    numeric_data = data.select_dtypes(include=[np.number])

    numeric_data = numeric_data.replace(0, np.nan).dropna()
    log_data = np.log(numeric_data)
    geometric_mean = gmean(numeric_data, axis=1).reshape(-1, 1)
    clr_data = log_data - np.log(geometric_mean)
    return clr_data

clr_data = clr_transform(Gold_data.iloc[:, 1:])

pca = PCA(n_components=2)
pca.fit(clr_data)

loadings = pca.components_.T

elements = clr_data.columns

plt.figure(figsize=(8, 8))

for i, element in enumerate(elements):
    plt.arrow(0, 0, loadings[i, 0], loadings[i, 1],
              color='black', alpha=0.65, head_width=0.02, head_length=0.02)
    plt.text(loadings[i, 0] * 0.7, loadings[i, 1] * 1.05, element, color='black', fontsize=16)

plt.xlabel('PC1')
plt.ylabel('PC2')
plt.xticks([])
plt.yticks([])
plt.title('')
plt.axis('equal')
plt.tight_layout()
plt.savefig('figure_6', dpi=300)
plt.show()

"""# 10-Fold Cross Validation Frame work, Machine Leaning Models Selection,Training, Evalution"""

import numpy as np
from numpy.linalg import pinv
from sklearn.ensemble import RandomForestClassifier, VotingClassifier, GradientBoostingClassifier
from sklearn.tree import DecisionTreeClassifier
from sklearn.neighbors import KNeighborsClassifier
from sklearn.neural_network import MLPClassifier
from sklearn.svm import SVC
from sklearn.preprocessing import StandardScaler
from sklearn.metrics import roc_curve, roc_auc_score, accuracy_score
from sklearn.model_selection import StratifiedKFold
import matplotlib.pyplot as plt
import pandas as pd

X = Gold_data_processed.drop(columns='Fertility')
y = Gold_data_processed['Fertility']

dt = DecisionTreeClassifier(max_depth=3, random_state=0)
knn = KNeighborsClassifier(n_neighbors=3)
rf = RandomForestClassifier(n_estimators=50, max_depth=5, random_state=0)
gb = GradientBoostingClassifier(n_estimators=50, learning_rate=0.1)
voting_clf = VotingClassifier(
    estimators=[('dt', dt), ('knn', knn), ('rf', rf), ('gb', gb)],
    weights=[1, 1, 1, 1], voting='soft'
)

classifiers = {
    "MLP": MLPClassifier(max_iter=500, hidden_layer_sizes=(10,)),
    "SVM": SVC(probability=True, C=0.5),
    "Random Forest": rf,
    "KNN": knn,
    "Gradient Boosting": gb,
    "Decision Tree": dt,
    "Ensemble": voting_clf,
}

mean_fpr = np.linspace(0, 1, 100)
roc_curves = {clf_name: {"tpr": [], "auc": []} for clf_name in classifiers.keys()}
cv = StratifiedKFold(n_splits=10, shuffle=True, random_state=0)

for clf_name, clf in classifiers.items():
    print(f"Training {clf_name}...")
    for train_idx, test_idx in cv.split(X, y):
        clf.fit(X.iloc[train_idx], y.iloc[train_idx])
        y_probs = clf.predict_proba(X.iloc[test_idx])[:, 1]
        fpr, tpr, _ = roc_curve(y.iloc[test_idx], y_probs)
        roc_curves[clf_name]["tpr"].append(np.interp(mean_fpr, fpr, tpr))
        roc_curves[clf_name]["tpr"][-1][0] = 0.0
        roc_auc = roc_auc_score(y.iloc[test_idx], y_probs)
        roc_curves[clf_name]["auc"].append(roc_auc)

class KernelELM:
    def __init__(self, C):
        self.C = C

    def fit(self, kernel_matrix, y):
        self.classes_ = np.unique(y)
        y_onehot = np.zeros((y.size, self.classes_.size))
        for idx, cls in enumerate(self.classes_):
            y_onehot[y == cls, idx] = 1
        n = kernel_matrix.shape[0]
        self.beta = pinv(kernel_matrix + np.eye(n) / self.C) @ y_onehot

    def predict_proba(self, kernel_matrix):
        y_pred = kernel_matrix @ self.beta
        return y_pred / y_pred.sum(axis=1, keepdims=True)

def normalize_matrix(X):
    X_min = X.min(axis=0)
    X_max = X.max(axis=0)
    return (X - X_min) / (X_max - X_min)

def type2_fuzzy_set(X, infl):
    mu_A = normalize_matrix(X)
    mu_upper = mu_A ** infl
    mu_lower = mu_A ** (1 / infl)
    return mu_upper, mu_lower

def hamacher_conorm(mu_upper, mu_lower, lam):
    num = mu_upper + mu_lower + (lam - 2) * mu_upper * mu_lower
    denom = 1 - (1 - lam) * mu_upper * mu_lower
    return (num / denom).mean()

def omega_kernel(X, Y, sigma, infl, alpha, lam):
    sq_dists = np.sum(X ** 2, axis=1).reshape(-1, 1) + np.sum(Y ** 2, axis=1) - 2 * np.dot(X, Y.T)
    mu_upper, mu_lower = type2_fuzzy_set(X, infl=infl)
    mu_prime = hamacher_conorm(mu_upper, mu_lower, lam)
    return mu_prime * np.exp(-sq_dists / (2 * sigma ** 2))

best_params = {
    'C': 32768,
    'sigma': 0.8,
    'infl': 0.7,
    'alpha': 0.9,
    'lam': 3.5
}

scaler = StandardScaler()
X_scaled = scaler.fit_transform(X)
K = omega_kernel(X_scaled, X_scaled, best_params['sigma'], best_params['infl'], best_params['alpha'], best_params['lam'])

kernel_elm = KernelELM(C=best_params['C'])

roc_curves["FKELM"] = {"tpr": [], "auc": []}
for train_idx, test_idx in cv.split(X, y):
    K_train = K[np.ix_(train_idx, train_idx)]
    K_test = K[np.ix_(test_idx, train_idx)]
    kernel_elm.fit(K_train, y.iloc[train_idx])
    y_probs = kernel_elm.predict_proba(K_test)[:, 1]
    fpr, tpr, _ = roc_curve(y.iloc[test_idx], y_probs)
    roc_curves["FKELM"]["tpr"].append(np.interp(mean_fpr, fpr, tpr))
    roc_curves["FKELM"]["tpr"][-1][0] = 0.0
    roc_auc = roc_auc_score(y.iloc[test_idx], y_probs)
    roc_curves["FKELM"]["auc"].append(roc_auc)

plt.figure(figsize=(10, 8))
plt.plot([0, 1], [0, 1], linestyle='--', color='grey', label='Random Classifier')

for clf_name, data in roc_curves.items():
    mean_tpr = np.mean(data["tpr"], axis=0)
    mean_tpr[-1] = 1.0
    mean_auc = np.mean(data["auc"])
    plt.plot(mean_fpr, mean_tpr, label=f'{clf_name} (AUC = {mean_auc:.2f})')

plt.xlabel('False Positive Rate')
plt.ylabel('True Positive Rate')
plt.title('Receiver Operating Characteristic (ROC) AUC Curve')
plt.legend(loc='lower right')
plt.savefig('figure_7', dpi=300)
plt.show()

plt.figure(figsize=(12, 10))

for i, (clf_name, roc_data) in enumerate(roc_curves.items(), start=1):
    plt.subplot(3, 3, i)

    for tpr in roc_data["tpr"]:
        plt.plot(mean_fpr, tpr, color='grey', alpha=0.3)

    mean_tpr = np.mean(roc_data["tpr"], axis=0)
    mean_tpr[-1] = 1.0
    mean_auc = np.mean(roc_data["auc"])
    plt.plot(mean_fpr, mean_tpr, color='red', linewidth=2, label=f'Mean ROC (AUC = {mean_auc:.2f})')

    plt.plot([0, 1], [0, 1], linestyle='--', color='grey', alpha=0.5)

    plt.xlabel('False Positive Rate')
    plt.ylabel('True Positive Rate')
    plt.title(f'ROC Curves - {clf_name}')
    plt.legend(loc='lower right')

plt.tight_layout()
plt.savefig('figure_8', dpi=300)
plt.show()

from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score

results = {clf_name: {"accuracy": [], "precision": [], "recall": [], "f1": []} for clf_name in classifiers.keys()}
results["Kernel ELM"] = {"accuracy": [], "precision": [], "recall": [], "f1": []}

for clf_name, clf in classifiers.items():
    for train_idx, test_idx in cv.split(X, y):
        clf.fit(X.iloc[train_idx], y.iloc[train_idx])
        y_pred = clf.predict(X.iloc[test_idx])
        results[clf_name]["accuracy"].append(accuracy_score(y.iloc[test_idx], y_pred))
        results[clf_name]["precision"].append(precision_score(y.iloc[test_idx], y_pred, average="binary"))
        results[clf_name]["recall"].append(recall_score(y.iloc[test_idx], y_pred, average="binary"))
        results[clf_name]["f1"].append(f1_score(y.iloc[test_idx], y_pred, average="binary"))

for train_idx, test_idx in cv.split(X, y):
    K_train = K[np.ix_(train_idx, train_idx)]
    K_test = K[np.ix_(test_idx, train_idx)]
    kernel_elm.fit(K_train, y.iloc[train_idx])
    y_probs = kernel_elm.predict_proba(K_test)
    y_pred = np.argmax(y_probs, axis=1)
    results["Kernel ELM"]["accuracy"].append(accuracy_score(y.iloc[test_idx], y_pred))
    results["Kernel ELM"]["precision"].append(precision_score(y.iloc[test_idx], y_pred, average="binary"))
    results["Kernel ELM"]["recall"].append(recall_score(y.iloc[test_idx], y_pred, average="binary"))
    results["Kernel ELM"]["f1"].append(f1_score(y.iloc[test_idx], y_pred, average="binary"))

print("\nClassifier Performance Metrics:")
for clf_name, metrics in results.items():
    print(f"\n{clf_name}:")
    print(f"  Accuracy:  {np.mean(metrics['accuracy']):.4f}")
    print(f"  Precision: {np.mean(metrics['precision']):.4f}")
    print(f"  Recall:    {np.mean(metrics['recall']):.4f}")
    print(f"  F1 Score:  {np.mean(metrics['f1']):.4f}")

import matplotlib.pyplot as plt
import numpy as np

features = ['As', 'Fe', 'S', 'Cu', 'Sb', 'Te', 'W', 'Zn']
importance_scores = [0.191, 0.212, 0.149, 0.125, 0.090, 0.109, 0.053, 0.071]

plt.figure(figsize=(12, 6))
bars = plt.bar(features, importance_scores, color='lightgrey', edgecolor='black')

for bar, score in zip(bars, importance_scores):
    plt.text(bar.get_x() + bar.get_width()/2, bar.get_height(), f'{score:.3f}',
             ha='center', va='bottom', fontsize=10)

plt.xlabel('Feature', fontsize=12, fontweight='bold')
plt.ylabel('Normalized Importance Score', fontsize=12, fontweight='bold')
plt.title('Feature Importance - FKELM Model', fontsize=14, fontweight='bold')

plt.tight_layout()
plt.savefig('figure_9', dpi=300)
plt.show()